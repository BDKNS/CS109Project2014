{
 "metadata": {
  "name": "",
  "signature": "sha256:ffb00991c4599c90511f89c3030bea5ea9dda2c5d65906cb2462faa8c333dba9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import requests\n",
      "from requests.auth import HTTPBasicAuth\n",
      "from requests.adapters import HTTPAdapter\n",
      "\n",
      "import json\n",
      "from pprint import pprint\n",
      "import pandas as pd # pandas\n",
      "import time\n",
      "import seaborn as sns\n",
      "import numpy as np\n",
      "import re\n",
      "\n",
      "\n",
      "subreddit_df = pd.read_csv('1000subreddits.csv')\n",
      "post_df = pd.read_csv('100postpersubreddit.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ids = list(post_df['user_id'])\n",
      "id_set = set(ids)\n",
      "print len(ids), len(id_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "40100 31365\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq = []\n",
      "for id in id_set:\n",
      "    freq.append(ids.count(id))\n",
      "for i in range(300):\n",
      "    print i, freq.count(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Basically all posts are unique except for one guy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Now let's try to get the users\n",
      "\n",
      "f = open('../secrets.txt', 'r')\n",
      "\n",
      "#These settings come from the apps preference settings on reddit\n",
      "#rstrip() removes the newline character\n",
      "\n",
      "user_name = f.readline().rstrip('\\n')\n",
      "user_password = f.readline().rstrip('\\n')\n",
      "app_id = f.readline().rstrip('\\n')\n",
      "app_secret = f.readline().rstrip('\\n')\n",
      "user_agent = f.readline().rstrip('\\n')\n",
      "f.close()\n",
      "\n",
      "#returns a JSON string, and an updated http session\n",
      "def getAuthToken(s):\n",
      " \n",
      "    #when using the reddit API we need to authenticate our APP, using app_id and app_secret\n",
      "    #we also need to provide the username and password for the user associated with the app\n",
      "    #Doing things this way lets use make up to 60 requests per minute to Reddit. Otherwise we are\n",
      "    #limited to 30 requests per minute\n",
      "    s.auth = (app_id, app_secret)\n",
      "    s.headers.update({\"User-Agent\": user_agent})\n",
      "    post_data = {\"grant_type\": \"password\", \"username\": user_name, \"password\": user_password}\n",
      "    response = s.post(\"https://ssl.reddit.com/api/v1/access_token\", data=post_data, )\n",
      "    time.sleep(1) # delay for 1 second, to make sure we don't get http error 429, too many requests\n",
      "\n",
      "    response.raise_for_status()\n",
      "\n",
      "    return s,response.json()\n",
      "\n",
      "def get_url(url):\n",
      "    try:\n",
      "        response = requests.get(url,headers=headers)\n",
      "        response.raise_for_status()\n",
      "    except requests.exceptions.RequestException as e:    \n",
      "        print e  \n",
      "    return response\n",
      "\n",
      "def get_domain(url):\n",
      "    #strip http:// out\n",
      "    url = re.sub('http\\:\\/\\/', '', url)\n",
      "    #in the initial run, I forgot to include https\n",
      "    url = re.sub('https\\:\\/\\/', '', url)\n",
      "\n",
      "    #strip out trailing URI details so only domain is left\n",
      "    return re.sub('/.*', '', url)\n",
      "\n",
      "\n",
      "#url from reddit we want a category for\n",
      "def get_category(url):\n",
      "    #build the URL to check the category\n",
      "    url = \"https://domain.opendns.com/\" + re.sub('http\\:\\/\\/', '', url)\n",
      "    response = get_url(url)\n",
      "    #This ugly regex is used to get the word Tagged: and the tags on the same line from\n",
      "    #the html\n",
      "    response = re.sub('re.sub(\"<.*?>\", \" \", html)', '', response.content.rstrip('\\n'))\n",
      "    response = re.sub('Tagged\\:\\n', 'Tagged:', response)\n",
      "    response = re.sub('\\<span class=\\\"normal\\\"\\>\\n', '', response)\n",
      "\n",
      "    #Find the line that contains the domain category information\n",
      "    reg_exp = re.compile(\"Tagged:(.*)\")\n",
      "    category = reg_exp.findall(response) \n",
      "\n",
      "    if len(category) > 0:\n",
      "        #onyl really care about the first response, should\n",
      "        #look into refactoring to use a different method\n",
      "        category = category[0]\n",
      "        category = re.sub('\\t+', '', category)\n",
      "        category = re.sub('\\</span\\>', '', category)\n",
      "        category = category.strip()\n",
      "    #    print response\n",
      "        return category\n",
      "    else:\n",
      "        return 'Not Categorized'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = requests.Session()\n",
      "\n",
      "#The next three lines authenticate us to Reddit\n",
      "s,response = getAuthToken(s)\n",
      "#s.headers = {\"Authorization\": (\"bearer \" + response['access_token']), \"User-Agent\": user_agent}\n",
      "#response = s.get(\"https://oauth.reddit.com\")\n",
      "headers = {\"Authorization\": (\"bearer \" + response['access_token']), \"User-Agent\": user_agent}\n",
      "\n",
      "\n",
      "#print response\n",
      "\n",
      "#Grab the 100 most popular subreddits\n",
      "response = get_url(\"https://oauth.reddit.com/subreddits/popular.json?limit=100\")\n",
      "response = json.loads(response.content)\n",
      "time.sleep(1.1)\n",
      "\n",
      "#Everything in reddit has an ID, and you can access items that come before\n",
      "#or after a specific ID\n",
      "after = response['data']['after']\n",
      "\n",
      "subreddits = []\n",
      "\n",
      "#add the first 100 subreddits to the subreddits array, \n",
      "#and grab the next 900 most popular subreddits\n",
      "for i in xrange(10):\n",
      "    for subreddit in response['data']['children']:\n",
      "        subreddits.append(subreddit['data'])\n",
      "    url = (\"https://oauth.reddit.com/subreddits/popular.json?limit=100&after=\"+after)\n",
      "    response = get_url(url)\n",
      "    response = json.loads(response.content)\n",
      "    after = response['data']['after']\n",
      "    #API rules require us to wait atleast 1 second between requests,\n",
      "    #but if you wait exactly 1 second, you will still get blocked, hence waiting\n",
      "    #1.05 seconds\n",
      "    time.sleep(1.05) \n",
      "    \n",
      "print \"Sanity chck to see how many subreddits we have: \",len(subreddits)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'requests' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-16920e72b644>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#The next three lines authenticate us to Reddit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetAuthToken\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#s.headers = {\"Authorization\": (\"bearer \" + response['access_token']), \"User-Agent\": user_agent}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "###### Getting the ideal name list\n",
      "\n",
      "url = 'https://www.reddit.com//user/OB1FBM/liked.json'\n",
      "\n",
      "res = requests.get(url)\n",
      "response = json.loads(res.content)\n",
      "\n",
      "response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "{u'error': 429}"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}