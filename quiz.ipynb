{
 "metadata": {
  "name": "",
  "signature": "sha256:8d79e95e12765630671123311cc5a9b22f82c43196fd8ea73db94f66baccd28d"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Libraries\n",
      "\n",
      "import requests\n",
      "import pandas as pd # pandas\n",
      "import time\n",
      "import seaborn as sns\n",
      "import numpy as np\n",
      "import re\n",
      "from csv import writer\n",
      "from sklearn.cluster import spectral_clustering\n",
      "from matplotlib.mlab import PCA as mlabPCA\n",
      "import json\n",
      "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
      "from sklearn.datasets.samples_generator import make_blobs\n",
      "from scipy.cluster.vq import kmeans, vq\n",
      "import random\n",
      "import networkx as nx\n",
      "from matplotlib import pyplot as plt\n",
      "from __future__ import division"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Constants\n",
      "\n",
      "TRAIN_FRACTION = 0.7\n",
      "NUM_POSTS_IN_QUIZ = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 99
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_agent = 'CS109 Data wrangling by BDKNS'\n",
      "def get_url(url):\n",
      "    headers = {\"User-Agent\": user_agent}\n",
      "\n",
      "    try:\n",
      "        response = requests.get(url,headers=headers)\n",
      "        #response.raise_for_status()\n",
      "    except requests.exceptions.RequestException as e:\n",
      "        print e\n",
      "    return response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('good_users_long.txt') as f:\n",
      "    good_users = f.readlines()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_good_users = len(good_users)\n",
      "num_train_users = int(num_good_users*TRAIN_FRACTION)\n",
      "good_users_train = good_users[:num_train_users]\n",
      "good_users_test = good_users[num_train_users:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 101
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_id = good_users_train[15]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = get_url('https://www.reddit.com//user/' + str(test_id).rstrip('\\n') + '/liked.json')\n",
      "if res.status_code == 200:\n",
      "    response = json.loads(res.content)\n",
      "    for i in range(25):\n",
      "        print response['data']['children'][i]['data']['created']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1416381917.0\n",
        "1416176530.0\n",
        "1416159915.0\n",
        "1416188242.0\n",
        "1412770853.0\n",
        "1412258450.0\n",
        "1412017109.0\n",
        "1412009409.0\n",
        "1412006856.0\n",
        "1412006627.0\n",
        "1411503381.0\n",
        "1411247423.0\n",
        "1410402927.0\n",
        "1409868832.0\n",
        "1409778830.0\n",
        "1408677005.0\n",
        "1408558612.0\n",
        "1407942400.0\n",
        "1407448423.0\n",
        "1407444325.0\n",
        "1406252138.0\n",
        "1406252314.0\n",
        "1405904841.0\n",
        "1405790794.0\n",
        "1398530275.0\n"
       ]
      }
     ],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = get_url('https://www.reddit.com//user/' + str(test_id).rstrip('\\n') + '/liked.json')\n",
      "if res.status_code == 200:\n",
      "    response = json.loads(res.content)\n",
      "    for i in range(25):\n",
      "        print response['data']['children'][i]['data']['id']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2mpr6h\n",
        "2mi32f\n",
        "2mh9s7\n",
        "2mh8zv\n",
        "2infob\n",
        "2i347w\n",
        "2ht376\n",
        "2hsovk\n",
        "2hskmo\n",
        "2hsk81\n",
        "2h985o\n",
        "2gz6mx\n",
        "2g2a8r\n",
        "2fhp9c\n",
        "2fdz66\n",
        "2e8n2o\n",
        "2e3iyu\n",
        "2dfrp6\n",
        "2cx35b\n",
        "2cwvh9\n",
        "2bnch2\n",
        "2bncpv\n",
        "2b919c\n",
        "2b52mh\n",
        "241ag7\n"
       ]
      }
     ],
     "prompt_number": 104
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = get_url('https://www.reddit.com//user/' + str(test_id).rstrip('\\n') + '/liked.json')\n",
      "upvoted_ids = []\n",
      "if res.status_code == 200:\n",
      "    response = json.loads(res.content)\n",
      "    num_upvotes = len(response['data']['children'])\n",
      "    for i in range(num_upvotes):\n",
      "         upvoted_ids.append((response['data']['children'][i]['data']['created'],response['data']['children'][i]['data']['id']))\n",
      "\n",
      "# Note: posts in reverse chronological order, so test is first listed posts; train is later listed posts\n",
      "cutoff = int(num_upvotes*(1-TRAIN_FRACTION))\n",
      "sample_max_date = upvoted_ids[cutoff][0]\n",
      "sample_training_post_tuples = upvoted_ids[cutoff:]\n",
      "sample_test_post_tuples = upvoted_ids[:cutoff]\n",
      "sample_training_posts = map(lambda tup: tup[1],sample_training_post_tuples)\n",
      "sample_test_posts = map(lambda tup: tup[1],sample_test_post_tuples)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Dario TODO\n",
      "#Does textual analysis comparing training posts to test_post and returns float between 0 (bad) and 1 (good) indicating fit\n",
      "#May also use other information (user posts, comments, etc.) but they must be before max_date\n",
      "def textual_analysis(training_posts, max_date, test_post):\n",
      "    pass\n",
      "    return 1\n",
      "\n",
      "#Shawn TODO\n",
      "#Does category analysis comparing training posts to test_post and returns float between 0 (bad) and 1 (good) indicating fit.\n",
      "#May also use other information (user posts, comments, etc.) but they must be before max_date\n",
      "def category_analysis(training_posts, max_date, test_post):\n",
      "    pass\n",
      "    return 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 106
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "post_df = pd.read_csv('../post.csv')\n",
      "max_date =1413000000\n",
      "viable_post_df = post_df[post_df['published_date'] > max_date]\n",
      "viable_post_df.head()\n",
      "ids = viable_post_df['id']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0     2narth\n",
        "2     2n99ak\n",
        "3     2na8v9\n",
        "4     2n8bzn\n",
        "5     2nc4rv\n",
        "6     2n8bgy\n",
        "7     2n76zy\n",
        "8     2n8iwt\n",
        "9     2n7eii\n",
        "10    2n9q3f\n",
        "11    2n8qo2\n",
        "12    2ndo15\n",
        "13    2n5ori\n",
        "14    2ljxbt\n",
        "15    2ne54t\n",
        "...\n",
        "102712    2n97wk\n",
        "102713    2n8cbi\n",
        "102714    2n6os5\n",
        "102715    2nbkgj\n",
        "102716    2n5zot\n",
        "102717    2n8nkz\n",
        "102718    2n77bd\n",
        "102719    2n8bjc\n",
        "102720    2n8js5\n",
        "102721    2n7phn\n",
        "102722    2n6ilj\n",
        "102723    2n81wk\n",
        "102724    2n64kk\n",
        "102725    2n6fdq\n",
        "102726    2nayt5\n",
        "Name: id, Length: 96376, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 107
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generate_quiz(max_date, test_post, all_test_posts):    \n",
      "    viable_post_df = post_df[post_df['published_date'] > max_date]\n",
      "    viable_ids = list(viable_post_df['id'])\n",
      "    options = []\n",
      "    while len(options) < NUM_POSTS_IN_QUIZ - 1:\n",
      "        option = random.choice(viable_ids)\n",
      "        if not (option in all_test_posts):\n",
      "            options.append(option)\n",
      "    index = random.randint(0,NUM_POSTS_IN_QUIZ-1)\n",
      "    options.insert(index,test_post)\n",
      "    return ((options, test_post))\n",
      "\n",
      "\n",
      "def test_classifier(training_posts, max_date, test_posts):\n",
      "    successes = 0\n",
      "    failures = 0\n",
      "    for test_post in test_posts:\n",
      "        quiz, correct_answer = generate_quiz(max_date, test_post, test_posts)\n",
      "        quiz_vals = []\n",
      "        for option in quiz:\n",
      "            category_val = category_analysis(training_posts, max_date, test_post)\n",
      "            textual_val = textual_analysis(training_posts, max_date, test_post)\n",
      "            \n",
      "            # right now just sum two mechanisms. We could experiment with weighted average, product, etc.\n",
      "            total_val = category_val + textual_val\n",
      "            \n",
      "            quiz_vals.append((option, total_val))\n",
      "        quiz_vals.sort(key=lambda tup: tup[1])\n",
      "        if quiz_vals[-1][0] == correct_answer:\n",
      "            successes += 1\n",
      "        else:\n",
      "            failures += 1\n",
      "    return successes / (successes + failures)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 112
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_classifier([11,22,33,44,55,66,77,88,99],123456789,[110,220,330,440,550,660,770,880,990])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 114,
       "text": [
        "0.1111111111111111"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print test_classifier(sample_training_posts, sample_max_date, sample_test_posts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.142857142857\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}